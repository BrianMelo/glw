%\VignetteIndexEntry{glw}
%\VignetteEngine{R.rsp::tex}
%\VignetteKeyword{R}
%\VignetteKeyword{package}
%\VignetteKeyword{vignette}
%\VignetteKeyword{LaTeX}

\documentclass[nojss]{jss}
\usepackage{amsmath}
\usepackage{amsfonts}

\author{}
\title{\pkg{GLW} Package}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{} %% comma-separated
\Plaintitle{} %% without formatting
\Shorttitle{} %% a short title (if necessary)

\Abstract{The \pkg{glw} package is an environment made to analyse data (censored or not) through regression models considering a finite mixture where the comoponents are the Gamma, Lognormal and Weibull densities, the GLW mixture.}
\Keywords{Finite mixtures, Censored data, Bayesian estimation, R}


\newcommand{\bs}[1]{\boldsymbol#1}

\begin{document}

\section{The glw finite mixture}

The GLW mixture is a finite mixture with three components, the densities from the Gamma, Lognormal and Weibull distributions, which are written in terms of the mean, $\mu$, and the variance, $\sigma^2$. Thus, the densiity function of the GLW model is
\begin{align}
\label{dens.T}
f(t_i|\bs\theta) &= p_1f_1(t_i|\mu, \sigma) + p_2f_2(t_i|\mu, \sigma) + p_3f_3(t_i|\mu, \sigma) \nonumber
\\[0.2cm]
&= \sum_{j=1}^3 p_j f_j(t_i|\mu, \sigma) \; , \quad t_i>0, 
\end{align}
where $\bs\theta = (\mu, \sigma, {\bf p})$, $p_j>0$, $j=1,2,3$ and $\sum_{j=1}^3=1$ are the mixture weights,  $f_1(.|\mu, \sigma)$, $f_2(.|\mu, \sigma)$ and $f_3(.|\mu, \sigma)$ are the densities of the Gamma, Lognormal and Weibull distributions, respectively. 

Similarly, the survival function is
\begin{align}
S(y |\bs\theta) = p_1 S_1(y|(\mu, \sigma)) + p_2 S_2(y| (\mu, \sigma)) + p_3 S_3(y | (\mu, \sigma)),
\end{align}
where $S_j(.|.)$, is the survival function associated with the density $f_j(.|.)$, $j=1,2,3$.

To acommodate censored data, we insert the following notation:
\begin{itemize}
	\item $T_i$ - survival time;
	\item $(L_i, R_i]$ - censorship interval;
	\item $Y_i = max\{min\{T_i, R_i\}, L_i\}$ - observed time;
	\item $\bs\delta_i = (\mathbb{I}(Y_i = T_i), \mathbb{I}(Y_i = R_i), \mathbb{I}(Y_i = L_i))$ - censorship indicator.
\end{itemize}
The vectors $\bs\delta_i$, $i=1, \ldots, n$, assume the value $(0,0,1)$ if the $i^{th}$ observation is left censored, $(0,1,0)$ when it is right censored, $(1,0,0)$ when $y_i$ is a survival time and $(0,0,0)$ when it is interval censored, case in which we record the interval $y_i = (l_i, r_i]$. If $L_i=0$, then $Y_i = min\{T_i, R_i\}$ is a survival or right censored time. When $R_i=\infty$, then $Y_i = max\{T_i, L_i\}$ is a survival or left censored time. The observed data is $D = ({\bf y}, \bs\delta) = \{(y_1,\bs\delta_1), \ldots,  (y_n,\bs\delta_n)\}$. 

Assuming that the censorship is non-informative and independence between censor and survival times \citep{klein:96} the likelihood generated by $D$ is
\begin{align}
\label{veros.obs}
L(\bs{\theta}&|D) = \prod_{i=1}^n f(y_i, \bs\delta_i| {\bs\theta})
\\[0.2cm]
&\propto \prod_{i=1}^n \bigg(\sum_{j=1}^3p_j f_j(y_i)\bigg)^{\delta_{i1}} \bigg(\sum_{j=1}^3p_j S_j(y_i)\bigg)^{\delta_{i2}} \bigg(\sum_{j=1}^3p_j F_j(y_i)\bigg)^{\delta_{i3}} \bigg(\sum_{j=1}^3p_j \Big(F_j(r_i) - F_j(l_i)\Big) \bigg)^{1-\sum_l \delta_{il}} \nonumber
\end{align}
where $S_j(.)$ and $F_j(.)$ are the survival and cumulative distribution functions associated to the densities $f_j(.)$ (we consider  $f_j(.) =  f_j(.|\mu, \sigma)$), $j=1,2,3$. 

We insert covariates in the model using a linear predictor with a logarithmic link function on the mean through the equation
\begin{align}
\label{fint}
log(\mu_i) =  \textbf{x}_i^\top {\bs\beta} = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_r x_{ir} \;, \; i=1, \ldots, n,
\end{align}
where $\textbf{x}_i^\top = (1, x_{i1}, \ldots, x_{ir})$ is the vector of covariates for the $i^{th}$ observation. 
In order to obtain a more flexible, yet parsimonious, model we allow each mixture component to have its own intercept $\beta_0^j$. Thereby, we have
\begin{align}
\label{rint}
log(\mu_{ij}) = \beta^{(j)}_0 + \beta_{1} x_{i1} + \ldots + \beta_{r} x_{ir} \;, i=1, \ldots, n,
\end{align}
where the index $j$ refers to the mixture components.

\subsection{Prior and Posterior Distributions}
The likelihood of the GLW mixture is a sum with $3^n$ terms which means that there are no conjugated families \citep{bernardo:88}. So, we may consider any distribution with an adequated support to the parameters involved. The default prior distributions in the \pkg{glw} package are
\begin{itemize}
    \item $\bs\beta \sim Normal_q({\bf 0}, 10^2\mathbb{I})$;
    \item $\sigma^2 \sim Gamma(0.01, 0.01)$;
    \item $\textbf{p} \sim Dir(1,1,1)$;
\end{itemize}
where the subscript $q$ is the dimension of the vector $\bs\beta$ and $\mathbb{I}$ is the identity matrix.

The posterior distribution is given by:
\begin{align*}
\pi(\bs\theta | D) &\propto L(\bs\theta| D) \pi(\bs\theta) \nonumber
\\[0.2cm]
&\propto \prod_{i=1}^n\Big\{f(y_i, \delta_i|\bs\beta, \sigma, \textbf{p})\Big\} \pi(\bs\beta) \pi(\sigma^2) \pi(\textbf{p}),
\end{align*}
which is not known. So, the estimation procedure is based on MCMC samples generated from this posterior distribution through the \textit{Adaptive Metropolis} algorithm \cite{haario:01}.

\subsection{Cure Rate Models}

In the usual Survival Analysis models, we assume that the whole population is susceptible to the ocurrence of the event of interest. But, sometimes, this might not be the case. For example, when studying cancer recurrence time, a fraction of the population may never have cancer again. In scenarios like this we consider the cure rate (or long-term) models. In this Section we briefly describe the Standard Cure rate model \citep{berkson:52} and the Promotion Time model \citep{chen:99}.

\vspace{0.5cm}
{\bf {\large Standard Cure Rate Model}}
\vspace{0.5cm}

For the Standard cure rate model, we consider the (improper) populational survival function
\begin{align}
S_{pop}(y | \bs\psi) = \pi + (1-\pi)S(y |\bs\theta) \;, \; y \in \mathcal{R}, \; \pi\in(0,1) \; ,
\end{align}
where $\bs\psi = (\pi, \theta)$ is the proportion of cured patients and $S(.|\bs\theta)$ is the survival function of the individuals that are susceptible to the event of interest.

Thus, the distribution of the observed times ${\bf Y}$ and the censorship indicator $\bs\delta$ ($\delta_i=1$ if the $i^{th}$ observation is a failure time and $\delta_i=1$ if $y_i$ is a right censored time) is
\begin{align}
f_{pop}(y, \delta | \bs\psi) &\propto \Big(f_{pop}(y)| \bs\psi \Big)^{\delta} \Big(S_{pop}(y) | \bs\psi \Big)^{1-\delta} \nonumber
\\[0.2cm]
&= \bigg((1-\pi)\sum_{j=1}^3p_j f_j\Big(y|(\mu, \sigma)\Big)\bigg)^{\delta} \bigg(\pi + (1-\pi)\sum_{j=1}^3p_j S_j\Big(y|(\mu, \sigma)\Big)\bigg)^{1-\delta}
\end{align}

The covariates are incorporated in the model through the parameter $\pi$ using a $logit$ link function
\begin{align}
\label{pred.linear.cr}
g(\pi_i) = log\Bigg(\frac{\pi_i}{1-\pi_i}\Bigg) = {\bf x}_i^\top {\bs\beta} = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_r x_{ir} \;, \; i=1, \ldots, n,
\end{align}
where ${\bf x}_i^\top = (1, x_{i1}, \ldots, x_{ir})$ is the covariates vector for the $i^{th}$ observation and $\bs\beta^\top = (\beta_0, \beta_1, \ldots, \beta_r)$ are the regression coefficients.

Finally, the likelihood of the standard cure rate model, generated by $({\bf y}, \bs\delta) = \big((y_1, \delta_1), \ldots, (y_n, \delta_n)\big)$, is
\begin{align*}
\label{veros.cr}
L(\bs{\psi}|({\bf y}, \bs\delta)) &= \prod_{i=1}^n f_{pop}(y_i, \delta_i| {\bs\theta})
\\[0.2cm]
&\propto \prod_{i=1}^n \bigg((1-\pi_i)\sum_{j=1}^3p_j f_j\big(y_i|(\mu, \sigma)\big)\bigg)^{\delta_{i}} \bigg(\pi_i + (1-\pi_i)\sum_{j=1}^3p_j S_j\big(y_i|(\mu, \sigma)\big)\bigg)^{1-\delta_{i}} \; .
\end{align*}

\vspace{0.5cm}
{ \bf {\large Promotion Time Cure Rate Model}}
\vspace{0.5cm}

The populational survival function in the promotion time cure rate model is
\begin{align}
S_{pop}(y| \bs\psi) = e^{-\eta F(y|\bs\theta)} \;, \; y \in \mathcal{R}, \; \eta>0 \; ,
\end{align}
where $F(.|.)$ is the cdf of the susceptible individuals and the the proportion of cured is $e^{-\eta}$.

The covariates are incorporated in the model through the parameter $\eta$ using a $log$ link function
\begin{align}
\label{pred.linear.tp}
log(\eta_i) = {\bf x}_i^\top {\bs\beta} = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_r x_{ir} \;, \; i=1, \ldots, n.
\end{align}

Similarly to the standard model, it can be shown that the likelihood for the promotion time model is
\begin{align}
\label{veros.tp}
L(\bs{\psi}|({\bf y}, \bs\delta)) &= \prod_{i=1}^n f_{pop}(y_i, \delta_i| {\bs\theta}) \nonumber
\\[0.2cm]
&\propto \prod_{i=1}^n \bigg(\eta_i f(y_i|\bs\theta) e^{-\eta_i F(y_i|\bs\theta)}\bigg)^{\delta_{i}} \bigg( e^{-\eta_i F(y_i|\bs\theta)} \bigg)^{1-\delta_{i}} \; .
\end{align}


\subsection{Hypothesis Testing}

To assess the effect of the covariates we can test hypothesis of the form
\begin{align}
\label{hip.contraste}
\left\{ \begin{array}{l} 			
H: \mathbb{C} \bs\beta = {\bf 0}
\\[0.1cm]
A: \mathbb{C} \bs\beta \neq {\bf 0}
\end{array}
\right.
\end{align}
where $\mathbb{C}$ is a contrast matrix. 

We can also evaluate the need for the three components of the GLW mixture by performing hypothesis tests on the mixture weights. In this case, we consider the hypotheses
\begin{align}
\begin{array}{lcr}
\label{hip.pesos}
\left\{ \begin{array}{l} 			
H: p_j = 1 \quad (\Leftrightarrow p_i=0 \quad \forall \; i \neq j)
\\[0.1cm]
A: p_j < 1
\end{array}
\right. \quad \quad
& \mbox{and} \quad \quad
&\left\{ \begin{array}{l} 			
H: p_j = 0
\\[0.1cm]
A: p_j > 0
\end{array}
\right. .
\end{array}
\end{align}

The null hypotheses given by (\ref{hip.contraste}) and (\ref{hip.pesos}) are sharp hypotheses \citep{carlinhos:08}. So, to perform tests under the Bayesian framework, we consider the Full Bayesian Significance Test (FBST) \cite{carlinhos:99}, which gives us an evidence in favor of the null hypothesis $H$. The FBST has two steps. In the first step we must find the posterior maximum under the null hypothesis $H$, which involves an optimization procedure and is computed using the function \code{mode_glw(\ldots)}. The second step is an integration, wich is made using the MCMC sample.


\section{The glw package}

The estimation of the parameters of the models described in the previous Section is made through samples of their posterior distributions generated via MCMC simulation. So, in order to fit these models to some data, we constructed the \pkg{glw} package, which allows us to estimate the parameters, the survival curves, the predictive distributions, compute measures of model adequability to the data and perform hypothesis tests. We also developes some functions to generate data from the proposed models and we use the \pkg{LaplacesDemon} package \citep{ld1:package} to generate samples from the posterior distributions of the parameters.

%\subsection{\pkg{glw} Basic Functions}

The following functions allow us to compute the density, the cdf and generate data from the GLW mixture.
\begin{itemize}
	\item \code{dglw(x, P, Mu, S2)} returns the density of the GLW mixtue;

	\item \code{pglw(x, P, Mu, S2, lower.tail=T)} returns the cdf of the GLW mixtue;

	\item \code{rglw(n, P, Mu, S2)} generates a random sample of the GLW  mixture. 
\end{itemize}

The arguments of this functions are:

\begin{itemize}
	\item \code{x} quantile
	\item \code{P} vector containing the three mixture weights;
	\item \code{Mu} mean;
	\item \code{S2} variance;
	\item \code{lower.tail} logical; if TRUE (default), probabilities are $P[X <= x]$, otherwise, $P[X > x]$;
	\item \code{n} sample size.
\end{itemize}

If we want to generate samples on a regression model framework with possible left or right censored data, or from the standard or promotion time cure rate models we consider, respectively, the functions
\begin{itemize}
	\item \code{rglw3(n, Betas, X, P, Sigma, Pc = c(0, 0)) }	%Mudar funÃ§Ãµes do pacote no RStudio (Sigma=S2)
	\item \code{rscr_glw(n, Mu, Sigma, P, Betas, X, pc)}
	\item \code{rpt_glw(n, Mu, Sigma, P, Betas, X, pc)}
\end{itemize}
where we have
\begin{itemize}
	\item \code{n} sample size;
	\item \code{Betas} regression coefficients;
	\item \code{X} matrix of covariates (with first column of $1's$);
	\item \code{P} vector containing the three mixture weights;
	\item \code{Sigma} variance;
	\item \code{Pc} vector with probabiliity of right and left censored times.
	\item \code{Mu} mean for the time of the susceptible individuals;
	\item \code{pc} probablity of right censored times.
\end{itemize}

\vspace{0.5cm}
{\bf Examples}
\vspace{0.5cm}


\code{
\#\#\# Sample of size 10 \\
> rglw(n=10, P=c(0.2, 0.3, 0.5), Mu=10, Sigma=10)}
\begin{verbatim}
 [1] 13.490200  8.511048  6.556054  5.325755 13.226479 13.521355
 [7] 11.384301 17.026614 14.948169 11.447700
\end{verbatim}


\code{
\#\#\# Sample of size 10 with no covariates and 20\% of right censored times \\
> rglw3(n=10, Betas=2, X=as.matrix(rep(1,10)), P=c(0.2, 0.3, 0.5), Sigma=10, Pc=c(0.2, 0))}
\begin{verbatim}
               Y d  
 [1,]  7.4264029 1 1
 [2,]  8.0049152 0 1
 [3,]  0.2135202 0 1
 [4,]  6.8530548 1 1
 [5,]  7.2614250 1 1
 [6,]  2.9179881 0 1
 [7,]  8.8628923 1 1
 [8,]  6.5729715 0 1
 [9,]  3.4388514 1 1
[10,] 10.5202133 1 1
\end{verbatim}

\code{
\#\#\# Sample of Standard cure rate model with two groups with 30\% and 52\% of cured and 10\% of right censored times\\
\#\#\# This data will be analyzed to exemplify the other functions along this tutorial\\
 >  data <- rscr_glw(n=100, Mu=20, Sigma=10, P=c(0.2,0.3,0.5), Betas=c(log(0.3/0.7), 1), X=cbind(1, rbinom(100,1,0.5)), pc=0.10) \\
head(data)}
\begin{verbatim}
          Y D X[1] X[2] W
1 24.314015 1    1    1 0
2 25.223561 1    1    1 0
3  2.258646 0    1    1 1
4 94.651474 0    1    1 1
5 21.504615 1    1    0 0
6 15.316438 1    1    0 0
\end{verbatim}

\subsection{Fitting the GLW mixture to data}

To fit the glw mixture we consider three main comands \code{glwfm(\ldots)}, \code{glw_scr(\ldots)} and \code{glw_ptcr(\ldots)}for the models in (2), (6) and (9). They have the same arguments:
\begin{itemize}
	\item \code{parm0}: is the list of inital values. For the main model the order is: the first $J$ values are the initial values of the regression coefficients, where $J$ is the dimension of $\bs\beta$. The value at position $J+1$ is for the variance $\sigma^2$ and the remaining values are for the mixture weigths ${\bf P} = (P_1, P_2, P_3)$. On the cure rate models, the order is:
	the first position is the initial value for the mean $\mu$, the second is for the variance $\sigma^2$, the next positions are for the weights and the last positions are for the regression coefficients (related to the cure rate fraction).
	
	\item \code{Data}: is a list containing
	
	\begin{itemize}
		\item \code{y}: the observed times.
		\item \code{d}: the censorship indicator.
		\item \code{yf}: the end of the interval censored times
		\item \code{y}: the observed times
		\item \code{X}: matrix of covariates (model matrix). Vector of 1's when tere are no covariates.
		\item \code{rint}: logical; True or False indicating when to consider different intercepts (model \ref{rint}) or not (model \ref{fint}).
	\end{itemize}

	\item \code{Specs}: is a list containing some of the simulation parameters
	
	\begin{itemize}
		\item \code{Iterations}: total size of the MCMC generated sample.
		\item \code{Status}: number of Iterations that the simulations status will be printed on the console.
		\item \code{Thinning}: thinning of the generated sample.
		\item \code{Algorithm}: name of algorithm used in the generation of the MCMC sample. Usually \code{Algorithm=`AM'} for Adaptive Metropolis.
		\item \code{LogFile}: a path to where the log of the simulation should be printed
	\end{itemize}

	\item \code{Specs2}: is a list containing simulation parameters specific to the chosen algorithm. For `AM' algorith, the default is \code{Specs2 = list(Adaptive = 1000, 
    Periodicity = 100)}.
		
	\item \code{prior}: a list of the log of the prior distributions, except for the mixture weights, where we chose the values of the hyperparameter $\alpha$ from a Dirichlet distribution. The default is \code{prior=list(beta=`dnormv(beta, 0, 100, log=T)', sigma=`dexp(sigma, 1, log=T)', alpha==c(1,1,1)).} for the main model. For the cure rate model we may add the prior for the parameter $\mu$.
	
	\item \code{mixture}: the mixture to be fitted. Choices are
	
	\begin{itemize}
		\item \code{`glw'} for a Gamma-Lognormal-Weibull finite mixture;
		\item \code{`gl'} for a Gamma-Lognormal finite mixture;
		\item \code{`gw'} for a Gamma-Weibull finite mixture;
		\item \code{`lw'} for a Lognormal-Weibull finite mixture;
		\item \code{`g'} for a Gamma model;
		\item \code{`l'} for a Lognormal model;
		\item \code{`w'} for a Weibull model;
	\end{itemize}
\end{itemize}

\vspace{0.5cm}
{\bf Examples}
\vspace{0.5cm}

\code{\#\#\# Standard cure rate model fitted to simulated data, \\
\#\#\# The generated sample is stored in \code{glw_scr(\ldots)$Posterior1} \\
> N <- nrow(data)\\
> Y <- data$Y\\
> D <- data$D\\
> X <- data[,3:4]\\
\\[0.1cm]
> MyData <- list(y=Y, d=D, X=X)\\
> Specs <- list(Iterations=10**4, Status=10**3, Thinning=1,  Algorithm="AM", LogFile=`')\\
> prior <- list(beta='dnormv(beta, 0, 100, log=T)', mu='dgamma(sigma, 0.01, 0.01, log=T)', sigma='dgamma(sigma, 0.01, 0.01, log=T)')\\
> parm0 <- c(1, 1, rep(1/3,3), rep(0, ncol(X)))\\
\\[0.1cm]  
> Fit <- glw_scr(parm0=parm0, Data=MyData, Specs=Specs, prior=prior, mixture='glw')\\
\\[0.1cm]
> mcmc <- Fit$Posterior1\\
> round(colMeans(mcmc),2)
}
\begin{verbatim}
     mu   sigma    p[1]    p[2]    p[3] beta[1] beta[2] 
  20.17   10.46    0.32    0.27    0.41   -1.38    0.36 
\end{verbatim}

\subsection{CPO functions}

We can fit several models when working with the GLW mixture. We can use the LPML to find which model is best for the data, but first we need to compute the CPO. We have three different functions \code{cpo_glw} for the main model, \code{cpo_scr} for the standard cure rate model and \code{cpo_ptcr} for the promotion time model. These three functions have the same arguments

\begin{itemize}
	\item \code{parm}: matrix; a sample from the posterior distribution of the parameters, obtained by \code{Fit\$Posterior1}.
	\item \code{Data}: list; the same list used to fit the model.
	\item \code{mixture}: string; indicates wich mixture you considered in fitting the model.
\end{itemize}

Continuing the example, we compute the cpo and find the lpml as the sum of the logarithm of the cpo's

\code{
\#\#\# Computing the CPO for the standard cure rate model adjusted to data \\
cpo <- cpo_scr(mcmc, MyData, mixture='glw') \\
lpml <- sum(log(cpo)) ; lpml
}
\begin{verbatim}
[1] -189.1265
\end{verbatim}

\subsection{Hypothesis testing}

As mentioned before, to perform the FBST we need an optimization step. This is done in the \pkg{glw} package throught the functions \code{mode_glw} for the main model, \code{mode_scr} and \code{mode_pt} for the standard and promotion time cure rate models. The arguments of these functions are: \code{Data}, the same list used to fit the model plus the vector of inital values \code{initial.par}, \code{prior}, a list of the prior distributions, and \code{mixture}, a string indicating the mixture (same as before). These functions return a list, which contains the posterior mode, the value of the log-posterior evaluated at the mode, an indicator of convergence and a message, which come from the \code{optim} function.

In the example, we can asses the covariate effect testing the hypothesis $H: \beta_1=0$. To compute the FBST evidence in favor of $H$, first we must find the maximum of the (log) posterior under the null hypothesis, which is done using the following code

\code{
> fbst.data <- list(y=Y, d=D, X=rep(1,N), initial.par=colMeans(mcmc)[1:6]) \\
> mode <- mode_scr(fbst.data, prior, mixture='glw') ; mode
}
\begin{verbatim}
$Posterior.mode
     mu   sigma    p[1]    p[2]    p[3] beta[1] 
19.9654  9.5483  1.0000  0.0000  0.0000 -0.9884 

$value
[1] -202.5846

$Convergence
[1] 0

$message
NULL
\end{verbatim}
To compute the evidence we need the value of the log-posterior of each observation generated with the MCMC simulation. These values are stored in \code{Fit\$Monitor}.

\code{
LP <- Fit$Monitor 			\#Log-Posterior \\
1 - mean(LP>mode$value)
}
\begin{verbatim}
[1] 1
\end{verbatim}



%\subsection{Predictive distribution}
%
%generating from the glw model

\subsection{Estimating survival curves}

Similarly to the CPO and mode computations, there is also three functions to estimate the survival functions after we fitted the model. The first one is \code{surv_glw(\ldots)} and, for the cure rate models we have \code{Spop_scr(\ldots)} and \code{Spop_ptcr(\ldots)}. These three functions have the same parameters:

\begin{itemize}
	\item \code{parm}: matrix; a sample from the posterior distribution of the parameters, obtained by \code{Fit\$Posterior1}
	\item \code{y}: a vector of observed times
	\item \code{X}: a vector containing the covariates for one observation
	\item \code{mixture}: string indicating the mixture fitted to the data. For the \code{surv_glw} functions the options are only the mixtures (`glw', `gl', `gw', `lw'). For the other two functions we can also choose the Gamma, Lognormal or Weibull models (`g', `l', `w').
	\item \code{by}: increment of time
\end{itemize}

These functions return a list containing two objects: \code{\$surv} contains the estimated survival probabilities and \code{\$time} contains the respective times. To estimate the survival times for the two groups in our simulated data we need the following commands

\code{
\#\#\# Estimating the survival function\\
> S0 <- Spop_scr(mcmc, y=Y, X=c(1,0), mixture=`glw', by=0.01)\\
> S1 <- Spop_scr(mcmc, y=Y, X=c(1,1), mixture=`glw', by=0.01)\\[0.2cm]
> s0 <- S0$surv ; s1 <- S1$surv		\#\#\#	Survival Probabilities\\
> t0 <- S0$time	; t1 <- S1$time   \#\#\#	Time
\\[0.1cm]
> plot.data <- data.frame(s0, s1, t0, t1)
> plot <- ggplot(plot.data, aes(x=t0, y=s0)) + geom_line(size=1.05) + xlab('Time') + ylab('Estimated Survival') + ylim(0,1) + xlim(10,50) +
	geom_line(aes(x=t1, y=s1), size=1.05, col=2) ; plot
}
\begin{figure}[h]
	\centering
		\includegraphics[width=0.5\textwidth]{Surv.pdf}
	\caption{Estimated survival probabilities for the two groups}
	\label{fig:Surv}
\end{figure}


\bibliography{References}

\end{document}
